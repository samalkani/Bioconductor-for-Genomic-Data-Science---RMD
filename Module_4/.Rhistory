coxph(Y~prison + dose + clinic,data=addicts, method="efron")
coxph(Y~prison + dose + clinic,data=addicts, method="breslow")
coxph(Y~prison + dose + clinic,data=addicts, method="exact")
mod1=coxph(Y~prison + dose + clinic,data=addicts)
mod2=coxph(Y~prison + dose + clinic + clinic*prison + clinic*dose, data=addicts)
mod1
mod2
names(mod2)
mod2$loglik
mod2[[3]]
(-2)*(mod1$loglik[2]-mod2$loglik[2])
LRT=(-2)*(mod1$loglik[2]-mod2$loglik[2])
Pvalue = 1 - pchisq(LRT,2)
Pvalue
lrt.surv=function(mod.full,mod.reduced,df){
lrts=(-2)*(mod.full$loglik[2]-mod.reduced$loglik[2])
pvalue=1-pchisq(lrts,df)
return(pvalue)
}
lrt.surv(mod1,mod2, 2)
Y=Surv(addicts$survt,addicts$status==1)
coxph(Y~ prison + dose + strata(clinic),data = addicts)
coxph(Y~prison + dose + clinic:prison + clinic:dose + strata(clinic),data=addicts)
addicts$clinic2=addicts$clinic-2
summary(coxph(Y~prison + dose + clinic2:prison +
clinic2:dose+strata(clinic2),data=addicts))
Y=Surv(addicts$survt,addicts$status==1)
mod1=coxph(Y~prison + dose + clinic,data=addicts)
cox.zph(mod1,transform=rank)
plot(cox.zph(mod1,transform=rank),se=F,var='clinic')
# Run Cox unadjusted model
Y=Surv(addicts$survt,addicts$status==1)
mod1=coxph(Y~prison + dose + clinic, data=addicts)
# Adjusted Cox model with the adjustments as follows
# PRISON = 0, DOSE=70 AND CLINIC=2
# CREATE DATA FRAME FIRST
pattern1=data.frame(prison=0,dose=70,clinic=2)
pattern1
# use summary function to get the Cox adjusted survival estimates
summary(survfit(mod1,newdata=pattern1))
# plot of the adjusted survival curve
plot(survfit(mod1, newdata=pattern1),
conf.int=F,main="Adjusted survival for prison=0, dose=70, clinic=2")
# stratified cox model
mod3=coxph(Y~prison + dose + strata(clinic),data=addicts)
# stratified cox model controlling for PRISON and DOSE
# Creation of one observation data frame, with the mean for prison and dose.
pattern2=data.frame(prison=0.46,dose=60.40)
#Plotting adjusted survival curve with clinic as the strata
plot(survfit(mod3,newdata=pattern2), conf.int=F, lty=c("solid","dashed"),
col=c("red","green"), main="Survival curves for clinic, adjusted for prison and dose")
legend("topright",c("Clinic 1","Clinic 2"),lty=c("solid","dashed"), col=c("red","green"))
# Plotting adjusted log-log survival curves for clinic
plot(survfit(mod3,newdata = pattern2),fun="cloglog",
main="Log-Log curves for clinic, adjusted for prison and dose")
# Plotting adjusted log-log survival curves for clinic with the time scale not logged
sum.mod3=summary(survfit(mod3,newdata=pattern2))
# similar code to section 3
sum.mod4=data.frame(sum.mod3$strata,sum.mod3$time,sum.mod3$surv)
colnames(sum.mod4)=c("clinic","time","survival")
clinic1=sum.mod4[sum.mod4$clinic=="clinic=1",]
clinic2=sum.mod4[sum.mod4$clinic=="clinic=2",]
# plot
plot(clinic1$time,log(-log(clinic1$survival)),xlab="survival time in days",ylab="log-log survival",xlim=c(0,800),col=
"red",type='l',lty="solid", main="log-log curves stratified by
clinic, adjusted for prison, dose")
par(new=T)
plot(clinic2$time,log(-log(clinic2$survival)),axes=F,xlab=
"survival time in days",ylab="log-log survival",col="green",
type='l',lty="dashed")
legend("bottomright",c("Clinic 1","Clinic 2"), lty=c("solid","dashed"),col=c("red","green"))
par(new=F)
# Transforming the dataset into counting process (start, stop) format
# to run an extended Cox model
addicts.cp=survSplit(addicts,cut=addicts$survt[addicts$status==1],
end="survt", event="status",start="start")
nrow(addicts.cp)
# Creation of a new variable based on multiplying the variable dose with the log of the survival
# time. This variable is created because we suspect that the variable dose has failed the proportional
# hazards assumption.
addicts.cp$logtdose=addicts.cp$dose*log(addicts.cp$survt)
# For the new variable DOSE=ln(DOSE)*T, which varies over time we print observation 106
# who had an event at time = 35 days for a selected group of variables
addicts.cp[addicts.cp$id==106,c('id','start','survt','status','dose','logtdose')]
# Run the extended Cox model with the inclusion of predictors;
# PRISON, DOSE, and CLINIC, and  time dependent variable LOGTDOSE
coxph(Surv(addicts.cp$start,addicts.cp$survt,addicts.cp$status) ~
prison + dose + clinic + logtdose + cluster(id),data=addicts.cp)
# Running the extended Cox model with a time cutpoint of 365 days
# Essentially splitting the time of the study into observations
# below 365 days and observations above 365 days
addicts.cp365=survSplit(addicts,cut=365,end="survt", event="status",start="start")
# Defining the timepoint 365 days and the two time intervals (heaviside functions) above and below 365 days
addicts.cp365$hv1=addicts.cp365$clinic*(addicts.cp365$start<365)
addicts.cp365$hv2=addicts.cp365$clinic*(addicts.cp365$start>=365)
# Sort the dataset by variables ID and START
addicts.cp365=addicts.cp365[order(addicts.cp365$id,addicts.cp365$start),]
# Printout of the first 10 observations for selected variables
addicts.cp365[1:10,c('id','start', 'survt','status','clinic','hv1','hv2')]
# Running an extended Cox model with heaviside functions (time intervals)
# Define the object for the response variable
Y365=Surv(addicts.cp365$start,addicts.cp365$survt,addicts.cp365$status)
# Run the Cox extended model with the two heaviside functions
coxph(Y365 ~ prison + dose + hv1 + hv2 + cluster(id), data=addicts.cp365)
# Handling ties in the two different time intervals (heaviside functions)
coxph(Y365 ~ prison + dose +hv1 + hv2,data=addicts.cp365,method="breslow")
# Run Cox extended model with one heaviside function and the variable CLINIC
coxph(Y365 ~ prison + dose + clinic + hv2 + cluster(id),data=addicts.cp365)
# log-log survival vs time in days using log-time plot
plot(survfit(Y~addicts$clinic),fun="cloglog",xlab="time in days using log-
arithmic scale",ylab="log-log survival", main="log-log curves by clinic")
# Exponential AFT model
modpar1=survreg(Surv(addicts$survt,addicts$status) ~ prison + dose +
clinic,data=addicts,dist="exponential")
summary(modpar1)
# Weibull AFT model
modpar2=survreg(Surv(addicts$survt,addicts$status)
~ prison + dose + clinic,data=addicts,dist="weibull")
summary(modpar2)
# Use of predict function to estimate then median or any other quantile time to event
# for any pattern of co-variates
# Co-variate pattern; PRISON=1, DOSE=50 AND CLINIC=1
pattern1=data.frame(prison=1,dose=50,clinic=1)
pct=c(0.25,0.50,0.75)
days=predict(modpar2,newdata=pattern1,type="quantile",p=pct)
cbind(pct,days) # adds vectors pct and days to create a matrix containing both vectors
# Creating a plot for individual with covariate pattern;  PRISON=1, DOSE=50 AND CLINIC=1
pct2=0:100/100
days2=predict(modpar2,newdata=pattern1,type="quantile",p=pct2)
survival=1-pct2
plot(days2,survival,xlab="survival time in days",ylab="survival
probabilities",main="Weibull survival estimates for prison=0,
dose=50, clinic=1",xlim=c(0,800))
# log-logistic AFT model
modpar3=survreg(Surv(addicts$survt,addicts$status)~
prison + dose + clinic,data=addicts,dist="loglogistic")
summary(modpar3)
# Kaplan Meier (KM) estimates object
kmfit2=survfit(Surv(addicts$survt,addicts$status)~addicts$clinic)
plot(log(kmfit2$time),log(kmfit2$surv/(1-kmfit2$surv)))
# Re-run the stratified Cox model without the Frailty (random) component.
Y=Surv(addicts$survt,addicts$status==1)
coxph(Y~ prison + dose + strata(clinic),data=addicts)
# Run the stratified Cox model with Frailty (random) component.
coxph(Y~ prison + dose + strata(clinic) + frailty(clinic,distribution="gamma"),data=addicts)
# Run the Cox model without the CLINIC variable and without FRAILTY.
coxph(Y~ prison + dose,data=addicts)
# Run the Cox model without the CLINIC variable and with FRAILTY
coxph(Y~ prison + dose + frailty(clinic,distribution="gamma"),data=addicts)
# Detailed output for the Cox model without CLINIC variable and with FRAILTY
summary(coxph(Y~ prison + dose + frailty(clinic,distribution="gamma"), data=addicts))
library(base64enc)
install.packages("AHPtools")
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
plot(pressure)
sessionInfo()
sessionInfo()
sessionInfo()
load("C:/Users/Ajay_/S01 - Machine-Learning-A-Z-Codes-Datasets/Machine-Learning-A-Z-Codes-Datasets/Part 1 - Data Preprocessing/Section 2 -------------------- Part 1 - Data Preprocessing --------------------/R/.RData")
R.version.string
install.packages("updateR")
library(updateR)
updateR()
update.packages()
R.version.string
q()
q()
R.version
# 2. Load AnnotationHub
library(AnnotationHub)
# 3. Creating a local annotation hub
ah = AnnotationHub()
ah
# 4. Look at first element
ah[1]
library(rtracklayer)
# 7. Retrieving objects from annotation hub
ah[[1]]
unique(ah$dataprovider)
unique(ah$dataprovider)
# 9. Information on Species in the ah database
unique(ah$species)
# 11. Information Specific to Homo sapiens
ah = subset(ah, species == "Homo sapiens")
ah
# 12. Information specific to Histomodification
query(ah, "H3K4me3")
# 13. Information on a specific cell line and Histomodification
query(ah, c("H3K$me3", "Gm12876"))
library(BiocHubsShiny)
BiocHubsShiny()
ah = AnnotationHub()
ah
ah[1]
ah[1]
ah[[1]]
unique(ah$dataprovider)
unique(ah$species)
ah = subset(ah, species == "Homo sapiens")
ah
query(ah, "H3K4me3")
query(ah, c("H3K$me3", "Gm12878"))
BiocHubsShiny()
BiocHubsShiny(ah)
ah2 <- query(ah, "H3K4me3")
BiocHubsShiny(ah2)
ah = AnnotationHub()
ah
ah[1]
ah[[1]]
unique(ah$dataprovider)
unique(ah$species)
ah = subset(ah, species == "Homo sapiens")
ah
query(ah, "H3K4me3")
query(ah, c("H3K$me3", "Gm12878"))
ah2 <- query(ah, "H3K4me3")
ah2
BiocHubsShiny(ah2)
BiocHubsShiny()
query(ah, "H3K4me3")
BiocHubsShiny()
ah = AnnotationHub()
ah
ah[1]
ah[[1]]
unique(ah$dataprovider)
unique(ah$species)
ah = subset(ah, species == "Homo sapiens")
ah
query(ah, "H3K4me3")
query(ah, c("H3K$me3", "Gm12878"))
BiocHubsShiny()
# 13. Information on a specific cell line and Histomodification
query(ah, c("H3K4me3", "Gm12878"))
BiocHubsShiny()
print(ah_meta)
table(ah_meta)
View(ah)
view(ah_meta)
View(ah_meta)
table(ah_meta)
print(ah_meta)
table(ah_meta)
BiocHubsShiny()
print(ah_meta)
load("D:/Ajay Files/Genomic Data Science Courses/Genomic Data Science/Course 5 - Bioconductor for Genomic Data Science/Module_1/.RData")
load("D:/Ajay Files/Genomic Data Science Courses/Genomic Data Science/Course 5 - Bioconductor for Genomic Data Science/Module_1/.RData")
load("D:/Ajay Files/Genomic Data Science Courses/Genomic Data Science/Course 5 - Bioconductor for Genomic Data Science/Module_1/.RData")
write.csv(ah_meta)
setwd("D:/Ajay Files/Genomic Data Science Courses/Genomic Data Science/Course 5 - Bioconductor for Genomic Data Science/Module_4")
# Question 1
# 1. A. Installing Bioconductor package
# if (!require("BiocManager", quietly = TRUE))
#   install.packages("BiocManager")
# BiocManager::install()
# 1. B. Installing "yeastRNASeq" and "leeBamViews"
BiocManager::install(c("yeastRNASeq", "leeBamViews", “zebrafishRNASeq”), force = TRUE)
# 1. A. Installing Bioconductor package
# if (!require("BiocManager", quietly = TRUE))
#   install.packages("BiocManager")
# BiocManager::install()
# 1. B. Installing "yeastRNASeq" and "leeBamViews"
BiocManager::install(c("yeastRNASeq", "leeBamViews", "zebrafishRNASeq"), force = TRUE)
# 1. C. Troubleshooting installing packages
BiocManager::valid()
BiocManager::install(c(
"BiocParallel", "DESeq2", "oligo", "promises", "Rsamtools", "xml2"
), update = TRUE, ask = FALSE, force = TRUE)
# 1. D. Load "yeastRNASeq"
library(yeastRNASeq)
# 1. E. Pointer down to FASTQ file
fastqFilePath <- system.file("reads", "wt_1_f.fastq.gz", package = "yeastRNASeq")
# 1. F. Load Libraries
library(ShortRead)
library(Biostrings)
reads <- readFastq(fastqFilePath)
reads
DNAStringSet <- sread(reads)
DNAStringSet
# 1. H. Fraction of reads has an A in the 5th base
cm <- consensusMatrix(DNAStringSet, as.prob=TRUE, baseOnly=TRUE)
cm
# 1. H. Fraction of reads has an A in the 5th base
cm <- consensusMatrix(DNAStringSet, baseOnly=TRUE)
cm
# 1. H. Fraction of reads has an A in the 5th base
cm <- consensusMatrix(DNAStringSet, as.prob=TRUE, baseOnly=TRUE)
cm
cm['A', 5]
# Question 2
# This is a continuation of Question 1.
# What is the average numeric quality value of the 5th base of these reads?
# 2. A. Average numeric quality value of base 5
mean(as(quality(reads), "matrix")[,5])
# 3. A. Load "leeBamViews"
library(leeBamViews)
# 3. B. Pointer down to BAM file
bamFilePath <- system.file("bam", "isowt5_13e.bam", package="leeBamViews")
bamFilePath
# 3. C. Load “Rsamtools”
library(Rsamtools)
bamFile <- BamFile(bamFilePath)
bamFile
head(cm)
cm[1,5]
bamFile <- BamFile(bamFilePath)
bamFile
# 3. D. Focus on Scchr13, interval from 800,000 to 801,000
gr <- GRanges(seqnames = "Scchr13", ranges = IRanges(start = c(800000), end = c(801000)))
gr
params <- ScanBamParam(which = gr, what = scanBamWhat())
params
aln <- scanBam(bamFile, param = params)
aln
# 3. D. Focus on Scchr13, interval from 800,000 to 801,000
gr <- GRanges(seqnames = "Scchr13", ranges = IRanges(start = c(800000), end = c(801000)))
gr
params <- ScanBamParam(which = gr, what = scanBamWhat())
params
aln <- scanBam(bamFile, param = params)
head(aln)
# 4. B. Focus on the novel transcribed regions
bamView <- BamViews(bpaths)
# 4. A. Pointer down to the BAM file
bpaths <- list.files(system.file("bam", package="leeBamViews"), pattern = "bam$", full=TRUE)
# 4. B. Focus on the novel transcribed regions
bamView <- BamViews(bpaths)
BamViews()
gr_nt <- GRanges(seqnames="Scchr13", ranges=IRanges(start = c(807762), end = c(808068)))
gr_nt
bamRanges(bamView) <- gr_nt
bamRanges()
# 4. B. Focus on the novel transcribed regions
bamView <- BamViews(bpaths)
BamViews()
gr_nt <- GRanges(seqnames="Scchr13", ranges=IRanges(start = c(807762), end = c(808068)))
gr_nt
bamRanges(bamView) <- gr_nt
bamRanges()
bamRanges(bamView) <- gr_nt
bamRanges
aln_nt <- scanBam(bamView)
aln_nt
# 4. B. Focus on the novel transcribed regions
bamView <- BamViews(bpaths)
bamView
gr_nt <- GRanges(seqnames="Scchr13", ranges=IRanges(start = c(807762), end = c(808068)))
gr_nt
bamRanges(bamView) <- gr_nt
aln_nt <- scanBam(bamView)
aln_nt
# 4. C. Get sequences for each sample
alns <- lapply(aln_nt, function(xx) xx[[1]]$seq)
alns
# 4. C. Get sequences for each sample
alns <- lapply(aln_nt, function(xx) xx[[1]]$seq)
alns
# 4. D. Calculate the average number of reads across 8 the samples
alns_len_sum = 0
for (i in 1:length(alns)){
alns_len_sum = alns_len_sum + length(alns[i][[1]])
}
alns_len_sum / length(alns)
# 5. A. Load Libraries
library(oligo)
library(GEOquery)
# 5. B. Get data
getGEOSuppFiles("GSE38792")
untar("GSE38792/GSE38792_RAW.tar", exdir = "GSE38792/CEL")
# 5. C. Read data
celfiles <- list.files("GSE38792/CEL", full = TRUE)
rawData <- read.celfiles(celfiles)
# 5. D. Parse pData
filename <- sampleNames(rawData)
filename
pData(rawData)$filename <- filename
filename
sampleNames <- sub(".*_", "", filename)
sampleNames
sampleNames <- sub(".CEL.gz$", "", sampleNames)
sampleNames
sampleNames(rawData) <- sampleNames
sampleNames
pData(rawData)$group <- ifelse(grepl("^OSA", sampleNames(rawData)), "OSA", "Control")
rawData
SampleNames
# 5. D. Parse pData
filename <- sampleNames(rawData)
filename
pData(rawData)$filename <- filename
filename
sampleNames <- sub(".*_", "", filename)
sampleNames
sampleNames <- sub(".CEL.gz$", "", sampleNames)
sampleNames
sampleNames(rawData) <- sampleNames
sampleNames
pData(rawData)$group <- ifelse(grepl("^OSA", sampleNames(rawData)), "OSA", "Control")
sampleNames
# 5. D. Parse pData
filename <- sampleNames(rawData)
filename
pData(rawData)$filename <- filename
filename
sampleNames <- sub(".*_", "", filename)
sampleNames
sampleNames <- sub(".CEL.gz$", "", sampleNames)
sampleNames
sampleNames(rawData) <- sampleNames
sampleNames
pData(rawData)$group <- ifelse(grepl("^OSA", sampleNames(rawData)), "OSA", "Control")
rawData
# 5. E. Find "8149273" probeset
normData <- rma(rawData)
normData
loc <- match("8149273", rownames(normData))
loc
# 5. F. Average expression in control group
mean(exprs(normData[loc,])[1:8])
# 6. A. Load Library
library(limma)
# 6. B. Use limma to fit between control group and OSA group
normData$group <- factor(normData$group)
normData$group
design <- model.matrix(~normData$group)
design
fit <- lmFit(normData, design)
fit
fit <- eBayes(fit)
fit
# 6. C. Absolute value of logFC which has lowest P.value
abs(topTable(fit)$logFC[1])
fit_toptable <- topTable(fit)
fit_toptable
de <- subset(fit_toptable, adj.P.Val < 0.05)
de
# 8. B. Get OpenSea loci in RGsetEx with preprocess
rgSet <- preprocessFunnorm(RGsetEx)
# 8. A. Load Libraries
library(minfi)
library(minfiData)
# 8. B. Get OpenSea loci in RGsetEx with preprocess
rgSet <- preprocessFunnorm(RGsetEx)
rgSet
rg_opensea <- rgSet[c(getIslandStatus(rgSet) == "OpenSea")]
rg_opensea
# 8. C. Get Beta value in both group
rg_beta <- getBeta(rg_opensea)
rg_beta
normal <- mean(rg_beta[, c(1,2,5)])
normal
cancer <- mean(rg_beta[, c(3,4,6)])
cancer
# 8. C. Get Beta value in both group
rg_beta <- getBeta(rg_opensea)
head(rg_beta)
normal <- mean(rg_beta[, c(1,2,5)])
normal
cancer <- mean(rg_beta[, c(3,4,6)])
cancer
# 8. D. Mean difference between normal and cancer group
normal - cancer
# 9. B. Get Caco2 data
ah <- AnnotationHub()
# 9. A. Load Library
library(AnnotationHub)
# 9. B. Get Caco2 data
ah <- AnnotationHub()
ah
ah <- subset(ah, species=="Homo sapiens")
ah
ah_Caco2 <- query(ah, c("Caco2", "AWG"))
ah_Caco2
ah_Caco2 <- ah_Caco2[["AH22442"]]
ah_Caco2
CpG_450K <- granges(rgSet)
CpG_450K
unique(findOverlaps(CpG_450K, ah_Caco2, type="within"))
# 10. A. Load Libraries
library(DESeq2)
library(zebrafishRNASeq)
# 10. B. Get and parse data
data("zfGenes")
data
zf <- zfGenes[grep("^ERCC", rownames(zfGenes), invert = T), ]
zf
zf <- as.matrix(zf)
zf
colData <- DataFrame(sampleID = colnames(zf), group = as.factor(c("control", "control", "control", "treatment", "treatment", "treatment")))
colData
# 10. B. Get and parse data
data("zfGenes")
data
zf <- zfGenes[grep("^ERCC", rownames(zfGenes), invert = T), ]
head(zf)
zf <- as.matrix(zf)
head(zf)
colData <- DataFrame(sampleID = colnames(zf), group = as.factor(c("control", "control", "control", "treatment", "treatment", "treatment")))
colData
# 10. C. Perform DESeq2
dds <- DESeqDataSetFromMatrix(zf, colData, design = ~ group)
dds
dds <- DESeq(dds)
dds
# 10. D. Find differentially expressed features
res <- results(dds)
res
sigRes <- subset(res, padj <= 0.05)
sigRes
dim(sigRes)[1]
